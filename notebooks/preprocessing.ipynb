{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c5872e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime  \n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "sns.set(font_scale=1.4, style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df189624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5556, 2)\n",
      "(3123, 4)\n",
      "(8900, 3)\n",
      "(2051, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "reddit_combi_df = pd.read_excel(r\"D:\\Stress-Detection\\data\\Reddit_Combi.xlsx\", engine='openpyxl')\n",
    "reddit_combi_df.head()\n",
    "reddit_title_df = pd.read_excel(r\"D:\\Stress-Detection\\data\\Reddit_Title.xlsx\", engine='openpyxl')\n",
    "twitter_full_df = pd.read_excel(r\"D:\\Stress-Detection\\data\\Twitter_Full.xlsx\", engine='openpyxl')\n",
    "twitter_non_ad_df = pd.read_excel(r\"D:\\Stress-Detection\\data\\Twitter_Non-Advert.xlsx\", engine='openpyxl')\n",
    "\n",
    "print(reddit_title_df.shape)\n",
    "print(reddit_combi_df.shape)\n",
    "print(twitter_full_df.shape)\n",
    "print(twitter_non_ad_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca810b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5556 entries, 0 to 5555\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   5556 non-null   object\n",
      " 1   label   5556 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 86.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3123 entries, 0 to 3122\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   title       3123 non-null   object\n",
      " 1   body        3116 non-null   object\n",
      " 2   Body_Title  3123 non-null   object\n",
      " 3   label       3123 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 97.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8900 entries, 0 to 8899\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      8900 non-null   object\n",
      " 1   hashtags  8892 non-null   object\n",
      " 2   labels    8900 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 208.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2051 entries, 0 to 2050\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2051 non-null   object\n",
      " 1   label   2051 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 32.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(reddit_title_df.info())\n",
    "print(reddit_combi_df.info())\n",
    "print(twitter_full_df.info())\n",
    "print(twitter_non_ad_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cbaafbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3116 entries, 0 to 3122\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   title       3116 non-null   object\n",
      " 1   body        3116 non-null   object\n",
      " 2   Body_Title  3116 non-null   object\n",
      " 3   label       3116 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 121.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8892 entries, 0 to 8899\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      8892 non-null   object\n",
      " 1   hashtags  8892 non-null   object\n",
      " 2   labels    8892 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reddit_combi_df.dropna(inplace=True)\n",
    "twitter_full_df.dropna(inplace=True)            \n",
    "print(reddit_combi_df.info())\n",
    "print(twitter_full_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef37a522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in Reddit Title dataframe:\n",
      "  Column 'title': 34 duplicates\n",
      "  Column 'label': 5554 duplicates\n",
      "\n",
      "Duplicates in Reddit Combi dataframe:\n",
      "  Column 'title': 25 duplicates\n",
      "  Column 'body': 4 duplicates\n",
      "  Column 'Body_Title': 0 duplicates\n",
      "  Column 'label': 3114 duplicates\n",
      "\n",
      "Duplicates in Twitter Full dataframe:\n",
      "  Column 'text': 459 duplicates\n",
      "  Column 'hashtags': 3322 duplicates\n",
      "  Column 'labels': 8890 duplicates\n",
      "\n",
      "Duplicates in Twitter Non-Ad dataframe:\n",
      "  Column 'text': 79 duplicates\n",
      "  Column 'label': 2049 duplicates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates in each column of each dataframe\n",
    "for df, name in zip([reddit_title_df, reddit_combi_df, twitter_full_df, twitter_non_ad_df],\n",
    "                    ['Reddit Title', 'Reddit Combi', 'Twitter Full', 'Twitter Non-Ad']):\n",
    "    print(f\"Duplicates in {name} dataframe:\")\n",
    "    for col in df.columns:\n",
    "        num_duplicates = df[col].duplicated().sum()\n",
    "        print(f\"  Column '{col}': {num_duplicates} duplicates\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ec74a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicates:\n",
      "(5513, 2)\n",
      "(3080, 4)\n",
      "(8410, 3)\n",
      "(1966, 2)\n",
      "Duplicates in Reddit Title dataframe:\n",
      "  Column 'title': 0 duplicates\n",
      "  Column 'label': 5511 duplicates\n",
      "\n",
      "Duplicates in Reddit Combi dataframe:\n",
      "  Column 'title': 0 duplicates\n",
      "  Column 'body': 0 duplicates\n",
      "  Column 'Body_Title': 0 duplicates\n",
      "  Column 'label': 3078 duplicates\n",
      "\n",
      "Duplicates in Twitter Full dataframe:\n",
      "  Column 'text': 0 duplicates\n",
      "  Column 'hashtags': 2967 duplicates\n",
      "  Column 'labels': 8408 duplicates\n",
      "\n",
      "Duplicates in Twitter Non-Ad dataframe:\n",
      "  Column 'text': 0 duplicates\n",
      "  Column 'label': 1964 duplicates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates in text columns, handle missing/empty values\n",
    "reddit_title_df = reddit_title_df.drop_duplicates(subset=['title'])\n",
    "reddit_combi_df = reddit_combi_df.drop_duplicates(subset=['title'])\n",
    "reddit_combi_df = reddit_combi_df.drop_duplicates(subset=['body'])\n",
    "twitter_full_df = twitter_full_df.drop_duplicates(subset=['text'])\n",
    "twitter_non_ad_df = twitter_non_ad_df.drop_duplicates(subset=['text'])\n",
    "print(\"After removing duplicates:\")\n",
    "print(reddit_title_df.shape)\n",
    "print(reddit_combi_df.shape)\n",
    "print(twitter_full_df.shape)\n",
    "print(twitter_non_ad_df.shape)\n",
    "\n",
    "for df, name in zip([reddit_title_df, reddit_combi_df, twitter_full_df, twitter_non_ad_df],\n",
    "                    ['Reddit Title', 'Reddit Combi', 'Twitter Full', 'Twitter Non-Ad']):\n",
    "    print(f\"Duplicates in {name} dataframe:\")\n",
    "    for col in df.columns:\n",
    "        num_duplicates = df[col].duplicated().sum()\n",
    "        print(f\"  Column '{col}': {num_duplicates} duplicates\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f12ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(text):\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9#]+\", ' ', text)\n",
    "    text = re.sub(r'\\n','', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "for df in [reddit_title_df, reddit_combi_df, twitter_full_df, twitter_non_ad_df]:\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].apply(pre_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing text:\n",
      "(5513, 2)\n",
      "(3080, 4)\n",
      "(8410, 3)\n",
      "(1966, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"After processing text:\")\n",
    "print(reddit_title_df.shape)\n",
    "print(reddit_combi_df.shape)\n",
    "print(twitter_full_df.shape)\n",
    "print(twitter_non_ad_df.shape)\n",
    "\n",
    "# processing did not remove any rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9353035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stress-Detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
